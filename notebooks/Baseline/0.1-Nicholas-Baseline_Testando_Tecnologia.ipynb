{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import sys,os\n",
    "\n",
    "#utils\n",
    "import paths\n",
    "\n",
    "#main libraries\n",
    "import pandas as pd\n",
    "\n",
    "#model Libraries\n",
    "import sklearn.linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#private modules\n",
    "from src.data import make_dataset\n",
    "\n",
    "from src.utils import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available memory (%): 31.290912628173828\n"
     ]
    }
   ],
   "source": [
    "memory_usage.memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 314 entries, id to target_kazutsugi\n",
      "dtypes: float64(311), object(3)\n",
      "memory usage: 12.0+ MB\n",
      "None\n",
      "CPU times: user 769 ms, sys: 431 ms, total: 1.2 s\n",
      "Wall time: 8.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_training,features,target = make_dataset.get_data(nrows=5000, low_memory=False, dataset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 314 entries, id to target_kazutsugi\n",
      "dtypes: float64(311), object(3)\n",
      "memory usage: 12.0+ MB\n",
      "None\n",
      "CPU times: user 1.37 s, sys: 895 ms, total: 2.27 s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tournament,features,target = make_dataset.get_data(nrows=5000, low_memory=False, dataset=\"tournament\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 85.3 ms, total: 2.8 s\n",
      "Wall time: 1.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import sklearn.linear_model\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(df_training[features], df_training[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 s, sys: 278 ms, total: 6.2 s\n",
      "Wall time: 2.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, n_jobs=-1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#encoding target to multiclass\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded_target = lab_enc.fit_transform(df_training[target])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "model.fit(df_training[features], encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99 s ± 148 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import parallel_backend\n",
    "\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    # Train the model\n",
    "    model = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "    model.fit(df_training[features], encoded_target)\n",
    "    # Test the model\n",
    "    #y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()  # Connect to a Dask Cluster\n",
    "\n",
    "with parallel_backend('dask', n_jobs=-1):\n",
    "    # Train the model\n",
    "    model = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "    model.fit(df_training[features], encoded_target)\n",
    "    # Test the model\n",
    "    #y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.66 s, sys: 207 ms, total: 5.86 s\n",
      "Wall time: 2.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, n_jobs=-1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#encoding target to multiclass\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded_target = lab_enc.fit_transform(df_training[target])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "model.fit(df_training[features], encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasrichers/Documents/virtualenvs/numerai_env/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 54822 instead\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  6.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 56s, sys: 1min 7s, total: 34min 4s\n",
      "Wall time: 9min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from dask.distributed import Client\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "client = Client(processes=False)             # create local cluster\n",
    "\n",
    "\n",
    "param_space =  {\n",
    "    #'bootstrap' : [True, False],\n",
    "    #'ccp_alpha' : 0.0, \n",
    "    #'class_weight': [None, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}, 'balanced'],\n",
    "    #'criterion' : 'gini', \n",
    "    #'max_depth' : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], \n",
    "    #'max_features' : ['auto', 'sqrt'],\n",
    "    #'max_leaf_nodes' : None,\n",
    "    #'max_samples' : None,\n",
    "    #'min_impurity_decrease' : 0.0, \n",
    "    #'min_impurity_split' : None,\n",
    "    #'min_samples_leaf' : [1, 2, 4],\n",
    "    #'min_samples_split' : [2, 5, 10],\n",
    "    #'min_weight_fraction_leaf' : 0.0, \n",
    "    'n_estimators' : [1000, 100],#200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'n_jobs' : [-1], \n",
    "    #'oob_score' : False, \n",
    "    #'random_state' : None,\n",
    "    #'verbose' : 0, \n",
    "    #'warm_start' : False\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "search = RandomizedSearchCV(model, param_space, cv=3, n_iter=2, verbose=1)\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    search.fit(df_training[features], encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 13s, sys: 1min 10s, total: 13min 23s\n",
      "Wall time: 9min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=2,\n",
       "                   param_distributions={'n_estimators': [1000, 100],\n",
       "                                        'n_jobs': [-1]},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "#from dask.distributed import Client\n",
    "\n",
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "#client = Client(processes=False)             # create local cluster\n",
    "\n",
    "\n",
    "\n",
    "param_space =  {\n",
    "    #'bootstrap' : [True, False],\n",
    "    #'ccp_alpha' : 0.0, \n",
    "    #'class_weight': [None, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}, 'balanced'],\n",
    "    #'criterion' : 'gini', \n",
    "    #'max_depth' : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], \n",
    "    #'max_features' : ['auto', 'sqrt'],\n",
    "    #'max_leaf_nodes' : None,\n",
    "    #'max_samples' : None,\n",
    "    #'min_impurity_decrease' : 0.0, \n",
    "    #'min_impurity_split' : None,\n",
    "    #'min_samples_leaf' : [1, 2, 4],\n",
    "    #'min_samples_split' : [2, 5, 10],\n",
    "    #'min_weight_fraction_leaf' : 0.0, \n",
    "    'n_estimators' : [1000, 100],#200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'n_jobs' : [-1], \n",
    "    #'oob_score' : False, \n",
    "    #'random_state' : None,\n",
    "    #'verbose' : 0, \n",
    "    #'warm_start' : False\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "search = RandomizedSearchCV(model, param_space, cv=3, n_iter=2, verbose=1)\n",
    "\n",
    " #with joblib.parallel_backend('dask'):\n",
    "search.fit(df_training[features], encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 314 entries, id to target_kazutsugi\n",
      "dtypes: float64(311), object(3)\n",
      "memory usage: 119.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_training,features,target = make_dataset.get_data(nrows=50000, low_memory=False, dataset=\"training\")\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded_target = lab_enc.fit_transform(df_training[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
